{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "58ba6aa5-5206-47b9-894e-a9276d5f1df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b317e6d-1298-4754-8f0e-7bcd0ba16bb3",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7031b65-6a3b-4220-8255-c1b9c1c0dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = os.path.join(\"..\", \"data\", \"IMDB Dataset.csv\")\n",
    "df = pd.read_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c789513c-ac0e-414e-a365-ed7318ce502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 35000\n",
      "Taille de l'ensemble de validation : 15000\n"
     ]
    }
   ],
   "source": [
    "X = df['review']  \n",
    "y = df['sentiment'] \n",
    "\n",
    "# Division en parties d'entraînement (80%) et de validation (20%)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Taille de l'ensemble d'entraînement :\", len(X_train))\n",
    "print(\"Taille de l'ensemble de validation :\", len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6b24d18b-f71d-4f2f-a2c7-27464ea06d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "50943c0f-290d-4b6d-b485-b81a33af55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame({'review': X_train}, columns=['review'])\n",
    "\n",
    "X_valid_df = pd.DataFrame({'review': X_valid}, columns=['review'])\n",
    "\n",
    "y_train_df = pd.DataFrame({'sentiment': y_train}, columns=['sentiment'])\n",
    "\n",
    "y_valid_df = pd.DataFrame({'sentiment': y_valid}, columns=['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a46825-4fde-4bca-983f-7b174a37a952",
   "metadata": {},
   "source": [
    "#### Preprocessing : label distribution , tokenization and lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c440098c-cf76-4706-8fee-d0bbd8ec9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_label_count  = df[df[\"sentiment\"] == \"positive\"].shape[0]\n",
    "negative_label_count = df[df[\"sentiment\"] == \"negative\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21b158f5-27af-457d-8579-60018e90c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_label_proportion = (positive_label_count / (positive_label_count+ negative_label_count))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3971ed7c-d887-4fa8-9d17-cb85b661bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_label_proportion= (negative_label_count / (positive_label_count+ negative_label_count))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3ae412b-7ce4-45a9-8305-514d81650505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la proportion de sentiments positives est de  50.0\n",
      "la proportion de sentiments négatifs est de  50.0\n"
     ]
    }
   ],
   "source": [
    "print('la proportion de sentiments positives est de ', positive_label_proportion)\n",
    "print('la proportion de sentiments négatifs est de ', negative_label_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf9d282c-868b-4946-a8e4-3cbce39a45f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on constate on a autant de labels positifs que de labels négatifs\n"
     ]
    }
   ],
   "source": [
    "print(\"on constate on a autant de labels positifs que de labels négatifs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32798eaa-6822-4029-9aee-5c6ce87ec9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pipeline:\n",
      "  tok2vec\n",
      "  tagger\n",
      "  lemmatizer\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "try:\n",
    "    #rem: enable does not seem to work, don't know why\n",
    "    nlp = spacy.load(\"en_core_web_sm\") #, enable=[\"tok2vec\", \"morphologizer\", \"lemmatizer\"])\n",
    "except OSError:\n",
    "    !python -m spacy download fr_core_news_md\n",
    "    nlp = spacy.load(\"en_core_web_sm\") #, enable=[\"tok2vec\", \"morphologizer\", \"lemmatizer\"])\n",
    "\n",
    "# we won't need ner, parser, attribute_ruler\n",
    "# NB: tok2vec and morphologizer seem to be necessary for lemmatization\n",
    "nlp.remove_pipe(\"ner\")\n",
    "nlp.remove_pipe(\"parser\")\n",
    "nlp.remove_pipe(\"attribute_ruler\")\n",
    "print('Current pipeline:\\n  '+'\\n  '.join(nlp.pipe_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1c2e24e6-3670-4775-bcdb-8aeeec091782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text) :\n",
    "    doc = nlp(text)\n",
    "    tokens =[token.text for token in doc ]\n",
    "    return tokens\n",
    "\n",
    "def lemmatize_text(text) :\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc ]\n",
    "    return lemmas \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "723a65a8-5560-4f7c-b865-5c77ca9ee58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moustapha/.local/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "X_valid_df['tokens'] = X_train_df['review'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "47ed6514-486e-4b82-b37e-53b6d36af1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moustapha/.local/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 55s, sys: 5.97 s, total: 8min 1s\n",
      "Wall time: 8min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_df['lemmas'] = X_train_df['review'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5afeb3dc-ff93-4a46-af1a-b0ee0000475e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As much as I love trains, I couldn't stomach t...</td>\n",
       "      <td>[As, much, as, I, love, trains, ,, I, could, n...</td>\n",
       "      <td>[as, much, as, i, love, trains, ,, i, could, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was a very good PPV, but like Wrestlemani...</td>\n",
       "      <td>[This, was, a, very, good, PPV, ,, but, like, ...</td>\n",
       "      <td>[this, was, a, very, good, ppv, ,, but, like, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not finding the right words is everybody's pro...</td>\n",
       "      <td>[Not, finding, the, right, words, is, everybod...</td>\n",
       "      <td>[not, finding, the, right, words, is, everybod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm really suprised this movie didn't get a hi...</td>\n",
       "      <td>[I, 'm, really, suprised, this, movie, did, n'...</td>\n",
       "      <td>[i, 'm, really, suprised, this, movie, did, n'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll start by confessing that I tend to really...</td>\n",
       "      <td>[I, 'll, start, by, confessing, that, I, tend,...</td>\n",
       "      <td>[i, 'll, start, by, confessing, that, i, tend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>`Shadow Magic' recaptures the joy and amazemen...</td>\n",
       "      <td>[`, Shadow, Magic, ', recaptures, the, joy, an...</td>\n",
       "      <td>[`, shadow, magic, ', recaptures, the, joy, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>I found this movie to be quite enjoyable and f...</td>\n",
       "      <td>[I, found, this, movie, to, be, quite, enjoyab...</td>\n",
       "      <td>[i, found, this, movie, to, be, quite, enjoyab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>Avoid this one! It is a terrible movie. So wha...</td>\n",
       "      <td>[Avoid, this, one, !, It, is, a, terrible, mov...</td>\n",
       "      <td>[avoid, this, one, !, it, is, a, terrible, mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>This production was quite a surprise for me. I...</td>\n",
       "      <td>[This, production, was, quite, a, surprise, fo...</td>\n",
       "      <td>[this, production, was, quite, a, surprise, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>This is a decent movie. Although little bit sh...</td>\n",
       "      <td>[This, is, a, decent, movie, ., Although, litt...</td>\n",
       "      <td>[this, is, a, decent, movie, ., although, litt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  \\\n",
       "0      As much as I love trains, I couldn't stomach t...   \n",
       "1      This was a very good PPV, but like Wrestlemani...   \n",
       "2      Not finding the right words is everybody's pro...   \n",
       "3      I'm really suprised this movie didn't get a hi...   \n",
       "4      I'll start by confessing that I tend to really...   \n",
       "...                                                  ...   \n",
       "34995  `Shadow Magic' recaptures the joy and amazemen...   \n",
       "34996  I found this movie to be quite enjoyable and f...   \n",
       "34997  Avoid this one! It is a terrible movie. So wha...   \n",
       "34998  This production was quite a surprise for me. I...   \n",
       "34999  This is a decent movie. Although little bit sh...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [As, much, as, I, love, trains, ,, I, could, n...   \n",
       "1      [This, was, a, very, good, PPV, ,, but, like, ...   \n",
       "2      [Not, finding, the, right, words, is, everybod...   \n",
       "3      [I, 'm, really, suprised, this, movie, did, n'...   \n",
       "4      [I, 'll, start, by, confessing, that, I, tend,...   \n",
       "...                                                  ...   \n",
       "34995  [`, Shadow, Magic, ', recaptures, the, joy, an...   \n",
       "34996  [I, found, this, movie, to, be, quite, enjoyab...   \n",
       "34997  [Avoid, this, one, !, It, is, a, terrible, mov...   \n",
       "34998  [This, production, was, quite, a, surprise, fo...   \n",
       "34999  [This, is, a, decent, movie, ., Although, litt...   \n",
       "\n",
       "                                                  lemmas  \n",
       "0      [as, much, as, i, love, trains, ,, i, could, n...  \n",
       "1      [this, was, a, very, good, ppv, ,, but, like, ...  \n",
       "2      [not, finding, the, right, words, is, everybod...  \n",
       "3      [i, 'm, really, suprised, this, movie, did, n'...  \n",
       "4      [i, 'll, start, by, confessing, that, i, tend,...  \n",
       "...                                                  ...  \n",
       "34995  [`, shadow, magic, ', recaptures, the, joy, an...  \n",
       "34996  [i, found, this, movie, to, be, quite, enjoyab...  \n",
       "34997  [avoid, this, one, !, it, is, a, terrible, mov...  \n",
       "34998  [this, production, was, quite, a, surprise, fo...  \n",
       "34999  [this, is, a, decent, movie, ., although, litt...  \n",
       "\n",
       "[35000 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "24c7ca01-fe54-46d9-bed9-2b94a6694a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire pour les tokens  : 146293\n",
      "Taille du vocabulaire pour les lemmes : 121716\n"
     ]
    }
   ],
   "source": [
    "tokens_vocab_size = len(set(token for tokens in X_train_df['tokens'] for token in tokens))\n",
    "lemmas_vocab_size = len(set(lemma for lemmas in X_train_df['lemmas'] for lemma in lemmas))\n",
    "print(\"Taille du vocabulaire pour les tokens  :\", tokens_vocab_size)\n",
    "print(\"Taille du vocabulaire pour les lemmes :\", lemmas_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f667b945-616c-4ddf-9cbb-5efe283110de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moustapha/.local/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "X_valid_df['tokens'] = X_valid_df['review'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "342283e4-4c6e-479f-be62-cd9bd691cbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>I really liked this Summerslam due to the look...</td>\n",
       "      <td>[I, really, liked, this, Summerslam, due, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>Not many television shows appeal to quite as m...</td>\n",
       "      <td>[Not, many, television, shows, appeal, to, qui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>The film quickly gets to a major chase scene w...</td>\n",
       "      <td>[The, film, quickly, gets, to, a, major, chase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>Jane Austen would definitely approve of this o...</td>\n",
       "      <td>[Jane, Austen, would, definitely, approve, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>Expectations were somewhat high for me when I ...</td>\n",
       "      <td>[Expectations, were, somewhat, high, for, me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15168</th>\n",
       "      <td>\"Landscape after a battle\" opens with escaping...</td>\n",
       "      <td>[\", Landscape, after, a, battle, \", opens, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49241</th>\n",
       "      <td>Jake Speed (1986) was an amusing parody of Ind...</td>\n",
       "      <td>[Jake, Speed, (, 1986, ), was, an, amusing, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39317</th>\n",
       "      <td>PLAN B has the appearance of a quickly made, u...</td>\n",
       "      <td>[PLAN, B, has, the, appearance, of, a, quickly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42191</th>\n",
       "      <td>One of the perks of my job is that when things...</td>\n",
       "      <td>[One, of, the, perks, of, my, job, is, that, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15109</th>\n",
       "      <td>Once you can get past the film's title, \"Pecke...</td>\n",
       "      <td>[Once, you, can, get, past, the, film, 's, tit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  \\\n",
       "33553  I really liked this Summerslam due to the look...   \n",
       "9427   Not many television shows appeal to quite as m...   \n",
       "199    The film quickly gets to a major chase scene w...   \n",
       "12447  Jane Austen would definitely approve of this o...   \n",
       "39489  Expectations were somewhat high for me when I ...   \n",
       "...                                                  ...   \n",
       "15168  \"Landscape after a battle\" opens with escaping...   \n",
       "49241  Jake Speed (1986) was an amusing parody of Ind...   \n",
       "39317  PLAN B has the appearance of a quickly made, u...   \n",
       "42191  One of the perks of my job is that when things...   \n",
       "15109  Once you can get past the film's title, \"Pecke...   \n",
       "\n",
       "                                                  tokens  \n",
       "33553  [I, really, liked, this, Summerslam, due, to, ...  \n",
       "9427   [Not, many, television, shows, appeal, to, qui...  \n",
       "199    [The, film, quickly, gets, to, a, major, chase...  \n",
       "12447  [Jane, Austen, would, definitely, approve, of,...  \n",
       "39489  [Expectations, were, somewhat, high, for, me, ...  \n",
       "...                                                  ...  \n",
       "15168  [\", Landscape, after, a, battle, \", opens, wit...  \n",
       "49241  [Jake, Speed, (, 1986, ), was, an, amusing, pa...  \n",
       "39317  [PLAN, B, has, the, appearance, of, a, quickly...  \n",
       "42191  [One, of, the, perks, of, my, job, is, that, w...  \n",
       "15109  [Once, you, can, get, past, the, film, 's, tit...  \n",
       "\n",
       "[15000 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a78f7e-5dd1-484b-b89e-cbcd14dbf8b6",
   "metadata": {},
   "source": [
    "#### Bag-of-Words\" (BoW) vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "18058daa-ed03-4bff-b3fc-2f50a98b614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.85, min_df=2, max_features=None, stop_words=None)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform([\" \".join(doc) for doc in X_train_df[\"tokens\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a82aad88-d932-4a0c-8f95-bf83b44591c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1447)\t0.1493097122938871\n",
      "  (0, 18975)\t0.06293896883695577\n",
      "  (0, 43875)\t0.04249173758699013\n",
      "  (0, 19445)\t0.1764950058221125\n",
      "  (0, 45207)\t0.06914440146338069\n",
      "  (0, 26953)\t0.05132252841035166\n",
      "  (0, 20278)\t0.1306669672020459\n",
      "  (0, 10208)\t0.13271826636134537\n",
      "  (0, 50884)\t0.1833670133075118\n",
      "  (0, 44441)\t0.13643068932689864\n",
      "  (0, 3687)\t0.1863370134256986\n",
      "  (0, 5362)\t0.11148535762233444\n",
      "  (0, 41460)\t0.12470861484962832\n",
      "  (0, 28814)\t0.09691601952673515\n",
      "  (0, 50140)\t0.04246419381736024\n",
      "  (0, 6649)\t0.025742473523883168\n",
      "  (0, 12763)\t0.1651702003383859\n",
      "  (0, 33876)\t0.06612525782477688\n",
      "  (0, 19470)\t0.03803616885733382\n",
      "  (0, 47449)\t0.07977678912156905\n",
      "  (0, 21157)\t0.15469643569182906\n",
      "  (0, 26605)\t0.19414905434794\n",
      "  (0, 4666)\t0.05101406750862695\n",
      "  (0, 31865)\t0.1898497779871838\n",
      "  (0, 36389)\t0.19414905434794\n",
      "  :\t:\n",
      "  (34999, 934)\t0.2307420710871859\n",
      "  (34999, 27864)\t0.06698885635286218\n",
      "  (34999, 2630)\t0.03574082572229232\n",
      "  (34999, 21402)\t0.12908472375445057\n",
      "  (34999, 19802)\t0.1617526157870924\n",
      "  (34999, 37037)\t0.06586370662136265\n",
      "  (34999, 7836)\t0.058472755923216525\n",
      "  (34999, 23049)\t0.10630957023139785\n",
      "  (34999, 41248)\t0.08482976631407849\n",
      "  (34999, 46272)\t0.09329944615810364\n",
      "  (34999, 17699)\t0.06072600382186473\n",
      "  (34999, 50919)\t0.046704016926642694\n",
      "  (34999, 4263)\t0.10869938573707358\n",
      "  (34999, 31630)\t0.033942925594541117\n",
      "  (34999, 50168)\t0.20712357101361478\n",
      "  (34999, 49151)\t0.04669089957696932\n",
      "  (34999, 49876)\t0.09698415942576835\n",
      "  (34999, 43875)\t0.049880499204113866\n",
      "  (34999, 26953)\t0.06024684992664223\n",
      "  (34999, 6649)\t0.030218755528442276\n",
      "  (34999, 19470)\t0.044650164906334\n",
      "  (34999, 51298)\t0.03629710826569726\n",
      "  (34999, 45857)\t0.05468444733327547\n",
      "  (34999, 30357)\t0.33752878018373866\n",
      "  (34999, 30413)\t0.0513970496526397\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbc443c-89b0-424b-9e7e-279b5fdcf0ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
