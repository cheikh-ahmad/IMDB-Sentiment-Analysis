{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "58ba6aa5-5206-47b9-894e-a9276d5f1df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b317e6d-1298-4754-8f0e-7bcd0ba16bb3",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7031b65-6a3b-4220-8255-c1b9c1c0dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = os.path.join(\"..\", \"data\", \"IMDB Dataset.csv\")\n",
    "df = pd.read_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c789513c-ac0e-414e-a365-ed7318ce502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 35000\n",
      "Taille de l'ensemble de validation : 15000\n"
     ]
    }
   ],
   "source": [
    "X = df['review']  \n",
    "y = df['sentiment'] \n",
    "\n",
    "# Division en parties d'entraînement (80%) et de validation (20%)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Taille de l'ensemble d'entraînement :\", len(X_train))\n",
    "print(\"Taille de l'ensemble de validation :\", len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6b24d18b-f71d-4f2f-a2c7-27464ea06d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "50943c0f-290d-4b6d-b485-b81a33af55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame({'review': X_train}, columns=['review'])\n",
    "\n",
    "X_valid_df = pd.DataFrame({'review': X_valid}, columns=['review'])\n",
    "\n",
    "y_train_df = pd.DataFrame({'sentiment': y_train}, columns=['sentiment'])\n",
    "\n",
    "y_valid_df = pd.DataFrame({'sentiment': y_valid}, columns=['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a46825-4fde-4bca-983f-7b174a37a952",
   "metadata": {},
   "source": [
    "#### Preprocessing : label distribution , tokenization and lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c440098c-cf76-4706-8fee-d0bbd8ec9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_label_count  = df[df[\"sentiment\"] == \"positive\"].shape[0]\n",
    "negative_label_count = df[df[\"sentiment\"] == \"negative\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21b158f5-27af-457d-8579-60018e90c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_label_proportion = (positive_label_count / (positive_label_count+ negative_label_count))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3971ed7c-d887-4fa8-9d17-cb85b661bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_label_proportion= (negative_label_count / (positive_label_count+ negative_label_count))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3ae412b-7ce4-45a9-8305-514d81650505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la proportion de sentiments positives est de  50.0\n",
      "la proportion de sentiments négatifs est de  50.0\n"
     ]
    }
   ],
   "source": [
    "print('la proportion de sentiments positives est de ', positive_label_proportion)\n",
    "print('la proportion de sentiments négatifs est de ', negative_label_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf9d282c-868b-4946-a8e4-3cbce39a45f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on constate on a autant de labels positifs que de labels négatifs\n"
     ]
    }
   ],
   "source": [
    "print(\"on constate on a autant de labels positifs que de labels négatifs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32798eaa-6822-4029-9aee-5c6ce87ec9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pipeline:\n",
      "  tok2vec\n",
      "  tagger\n",
      "  lemmatizer\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "try:\n",
    "    #rem: enable does not seem to work, don't know why\n",
    "    nlp = spacy.load(\"en_core_web_sm\") #, enable=[\"tok2vec\", \"morphologizer\", \"lemmatizer\"])\n",
    "except OSError:\n",
    "    !python -m spacy download fr_core_news_md\n",
    "    nlp = spacy.load(\"en_core_web_sm\") #, enable=[\"tok2vec\", \"morphologizer\", \"lemmatizer\"])\n",
    "\n",
    "# we won't need ner, parser, attribute_ruler\n",
    "# NB: tok2vec and morphologizer seem to be necessary for lemmatization\n",
    "nlp.remove_pipe(\"ner\")\n",
    "nlp.remove_pipe(\"parser\")\n",
    "nlp.remove_pipe(\"attribute_ruler\")\n",
    "print('Current pipeline:\\n  '+'\\n  '.join(nlp.pipe_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1c2e24e6-3670-4775-bcdb-8aeeec091782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text) :\n",
    "    doc = nlp(text)\n",
    "    tokens =[token.text for token in doc ]\n",
    "    return tokens\n",
    "\n",
    "def lemmatize_text(text) :\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc ]\n",
    "    return lemmas \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "723a65a8-5560-4f7c-b865-5c77ca9ee58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moustapha/.local/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "X_valid_df['tokens'] = X_train_df['review'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "47ed6514-486e-4b82-b37e-53b6d36af1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moustapha/.local/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 55s, sys: 5.97 s, total: 8min 1s\n",
      "Wall time: 8min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_df['lemmas'] = X_train_df['review'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5afeb3dc-ff93-4a46-af1a-b0ee0000475e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As much as I love trains, I couldn't stomach t...</td>\n",
       "      <td>[As, much, as, I, love, trains, ,, I, could, n...</td>\n",
       "      <td>[as, much, as, i, love, trains, ,, i, could, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was a very good PPV, but like Wrestlemani...</td>\n",
       "      <td>[This, was, a, very, good, PPV, ,, but, like, ...</td>\n",
       "      <td>[this, was, a, very, good, ppv, ,, but, like, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not finding the right words is everybody's pro...</td>\n",
       "      <td>[Not, finding, the, right, words, is, everybod...</td>\n",
       "      <td>[not, finding, the, right, words, is, everybod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm really suprised this movie didn't get a hi...</td>\n",
       "      <td>[I, 'm, really, suprised, this, movie, did, n'...</td>\n",
       "      <td>[i, 'm, really, suprised, this, movie, did, n'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll start by confessing that I tend to really...</td>\n",
       "      <td>[I, 'll, start, by, confessing, that, I, tend,...</td>\n",
       "      <td>[i, 'll, start, by, confessing, that, i, tend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>`Shadow Magic' recaptures the joy and amazemen...</td>\n",
       "      <td>[`, Shadow, Magic, ', recaptures, the, joy, an...</td>\n",
       "      <td>[`, shadow, magic, ', recaptures, the, joy, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>I found this movie to be quite enjoyable and f...</td>\n",
       "      <td>[I, found, this, movie, to, be, quite, enjoyab...</td>\n",
       "      <td>[i, found, this, movie, to, be, quite, enjoyab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>Avoid this one! It is a terrible movie. So wha...</td>\n",
       "      <td>[Avoid, this, one, !, It, is, a, terrible, mov...</td>\n",
       "      <td>[avoid, this, one, !, it, is, a, terrible, mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>This production was quite a surprise for me. I...</td>\n",
       "      <td>[This, production, was, quite, a, surprise, fo...</td>\n",
       "      <td>[this, production, was, quite, a, surprise, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>This is a decent movie. Although little bit sh...</td>\n",
       "      <td>[This, is, a, decent, movie, ., Although, litt...</td>\n",
       "      <td>[this, is, a, decent, movie, ., although, litt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  \\\n",
       "0      As much as I love trains, I couldn't stomach t...   \n",
       "1      This was a very good PPV, but like Wrestlemani...   \n",
       "2      Not finding the right words is everybody's pro...   \n",
       "3      I'm really suprised this movie didn't get a hi...   \n",
       "4      I'll start by confessing that I tend to really...   \n",
       "...                                                  ...   \n",
       "34995  `Shadow Magic' recaptures the joy and amazemen...   \n",
       "34996  I found this movie to be quite enjoyable and f...   \n",
       "34997  Avoid this one! It is a terrible movie. So wha...   \n",
       "34998  This production was quite a surprise for me. I...   \n",
       "34999  This is a decent movie. Although little bit sh...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [As, much, as, I, love, trains, ,, I, could, n...   \n",
       "1      [This, was, a, very, good, PPV, ,, but, like, ...   \n",
       "2      [Not, finding, the, right, words, is, everybod...   \n",
       "3      [I, 'm, really, suprised, this, movie, did, n'...   \n",
       "4      [I, 'll, start, by, confessing, that, I, tend,...   \n",
       "...                                                  ...   \n",
       "34995  [`, Shadow, Magic, ', recaptures, the, joy, an...   \n",
       "34996  [I, found, this, movie, to, be, quite, enjoyab...   \n",
       "34997  [Avoid, this, one, !, It, is, a, terrible, mov...   \n",
       "34998  [This, production, was, quite, a, surprise, fo...   \n",
       "34999  [This, is, a, decent, movie, ., Although, litt...   \n",
       "\n",
       "                                                  lemmas  \n",
       "0      [as, much, as, i, love, trains, ,, i, could, n...  \n",
       "1      [this, was, a, very, good, ppv, ,, but, like, ...  \n",
       "2      [not, finding, the, right, words, is, everybod...  \n",
       "3      [i, 'm, really, suprised, this, movie, did, n'...  \n",
       "4      [i, 'll, start, by, confessing, that, i, tend,...  \n",
       "...                                                  ...  \n",
       "34995  [`, shadow, magic, ', recaptures, the, joy, an...  \n",
       "34996  [i, found, this, movie, to, be, quite, enjoyab...  \n",
       "34997  [avoid, this, one, !, it, is, a, terrible, mov...  \n",
       "34998  [this, production, was, quite, a, surprise, fo...  \n",
       "34999  [this, is, a, decent, movie, ., although, litt...  \n",
       "\n",
       "[35000 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "24c7ca01-fe54-46d9-bed9-2b94a6694a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire pour les tokens  : 146293\n",
      "Taille du vocabulaire pour les lemmes : 121716\n"
     ]
    }
   ],
   "source": [
    "tokens_vocab_size = len(set(token for tokens in X_train_df['tokens'] for token in tokens))\n",
    "lemmas_vocab_size = len(set(lemma for lemmas in X_train_df['lemmas'] for lemma in lemmas))\n",
    "print(\"Taille du vocabulaire pour les tokens  :\", tokens_vocab_size)\n",
    "print(\"Taille du vocabulaire pour les lemmes :\", lemmas_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f667b945-616c-4ddf-9cbb-5efe283110de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moustapha/.local/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "X_valid_df['tokens'] = X_valid_df['review'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "342283e4-4c6e-479f-be62-cd9bd691cbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>I really liked this Summerslam due to the look...</td>\n",
       "      <td>[I, really, liked, this, Summerslam, due, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>Not many television shows appeal to quite as m...</td>\n",
       "      <td>[Not, many, television, shows, appeal, to, qui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>The film quickly gets to a major chase scene w...</td>\n",
       "      <td>[The, film, quickly, gets, to, a, major, chase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>Jane Austen would definitely approve of this o...</td>\n",
       "      <td>[Jane, Austen, would, definitely, approve, of,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>Expectations were somewhat high for me when I ...</td>\n",
       "      <td>[Expectations, were, somewhat, high, for, me, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15168</th>\n",
       "      <td>\"Landscape after a battle\" opens with escaping...</td>\n",
       "      <td>[\", Landscape, after, a, battle, \", opens, wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49241</th>\n",
       "      <td>Jake Speed (1986) was an amusing parody of Ind...</td>\n",
       "      <td>[Jake, Speed, (, 1986, ), was, an, amusing, pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39317</th>\n",
       "      <td>PLAN B has the appearance of a quickly made, u...</td>\n",
       "      <td>[PLAN, B, has, the, appearance, of, a, quickly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42191</th>\n",
       "      <td>One of the perks of my job is that when things...</td>\n",
       "      <td>[One, of, the, perks, of, my, job, is, that, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15109</th>\n",
       "      <td>Once you can get past the film's title, \"Pecke...</td>\n",
       "      <td>[Once, you, can, get, past, the, film, 's, tit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  \\\n",
       "33553  I really liked this Summerslam due to the look...   \n",
       "9427   Not many television shows appeal to quite as m...   \n",
       "199    The film quickly gets to a major chase scene w...   \n",
       "12447  Jane Austen would definitely approve of this o...   \n",
       "39489  Expectations were somewhat high for me when I ...   \n",
       "...                                                  ...   \n",
       "15168  \"Landscape after a battle\" opens with escaping...   \n",
       "49241  Jake Speed (1986) was an amusing parody of Ind...   \n",
       "39317  PLAN B has the appearance of a quickly made, u...   \n",
       "42191  One of the perks of my job is that when things...   \n",
       "15109  Once you can get past the film's title, \"Pecke...   \n",
       "\n",
       "                                                  tokens  \n",
       "33553  [I, really, liked, this, Summerslam, due, to, ...  \n",
       "9427   [Not, many, television, shows, appeal, to, qui...  \n",
       "199    [The, film, quickly, gets, to, a, major, chase...  \n",
       "12447  [Jane, Austen, would, definitely, approve, of,...  \n",
       "39489  [Expectations, were, somewhat, high, for, me, ...  \n",
       "...                                                  ...  \n",
       "15168  [\", Landscape, after, a, battle, \", opens, wit...  \n",
       "49241  [Jake, Speed, (, 1986, ), was, an, amusing, pa...  \n",
       "39317  [PLAN, B, has, the, appearance, of, a, quickly...  \n",
       "42191  [One, of, the, perks, of, my, job, is, that, w...  \n",
       "15109  [Once, you, can, get, past, the, film, 's, tit...  \n",
       "\n",
       "[15000 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a78f7e-5dd1-484b-b89e-cbcd14dbf8b6",
   "metadata": {},
   "source": [
    "#### Bag-of-Words\" (BoW) vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "18058daa-ed03-4bff-b3fc-2f50a98b614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.85, min_df=2, max_features=None, stop_words=None)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform([\" \".join(doc) for doc in X_train_df[\"tokens\"]])\n",
    "X_valid_tfidf = tfidf_vectorizer.transform([\" \".join(doc) for doc in X_valid_df[\"tokens\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8499c163-ef6a-434d-9214-27e3a6c54f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78cdc5ff-5a1b-4161-b05c-f6b53a16cbaf",
   "metadata": {},
   "source": [
    "### Apprentissage via une régression logistique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bcbc443c-89b0-424b-9e7e-279b5fdcf0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;ovr&#x27;, n_jobs=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;ovr&#x27;, n_jobs=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='ovr', n_jobs=2)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instance de classifieur de type \"régression logistique\"\n",
    "\n",
    "clf_f = LogisticRegression(\n",
    "        #random_state=0, \n",
    "        solver='lbfgs',    # algo d'optimisation (ici minimisation de la perte cross-entropie)\n",
    "        multi_class='ovr', # stratégie \"one versus rest\"\n",
    "        penalty='l2', # hyperparamètre de régularisation\n",
    "        C=1.0, # hyperparamètre de régularisation\n",
    "        n_jobs=2\n",
    ")\n",
    "\n",
    "clf_f.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "17ee7dc1-8ed0-4080-a5c4-269a4a7f8b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE OF LOGISTIC REGRESSION ON VALID: 0.901\n"
     ]
    }
   ],
   "source": [
    "Y_valid_pred_f = clf_f.predict(X_valid_tfidf)\n",
    "print(\"SCORE OF LOGISTIC REGRESSION ON VALID: %.3f\" % accuracy_score(y_valid, Y_valid_pred_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff42027b-3e22-4a23-9919-a5f01a30717c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
