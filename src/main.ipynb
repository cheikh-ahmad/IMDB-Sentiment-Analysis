{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "58ba6aa5-5206-47b9-894e-a9276d5f1df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b317e6d-1298-4754-8f0e-7bcd0ba16bb3",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f7031b65-6a3b-4220-8255-c1b9c1c0dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path = os.path.join(\"..\", \"data\", \"IMDB Dataset.csv\")\n",
    "df = pd.read_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c789513c-ac0e-414e-a365-ed7318ce502d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 35000\n",
      "Taille de l'ensemble de validation : 15000\n"
     ]
    }
   ],
   "source": [
    "X = df['review']  \n",
    "y = df['sentiment'] \n",
    "\n",
    "# Division en parties d'entraînement (80%) et de validation (20%)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Taille de l'ensemble d'entraînement :\", len(X_train))\n",
    "print(\"Taille de l'ensemble de validation :\", len(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6b24d18b-f71d-4f2f-a2c7-27464ea06d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "50943c0f-290d-4b6d-b485-b81a33af55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame({'review': X_train}, columns=['review'])\n",
    "\n",
    "X_valid_df = pd.DataFrame({'review': X_valid}, columns=['review'])\n",
    "\n",
    "y_train_df = pd.DataFrame({'sentiment': y_train}, columns=['sentiment'])\n",
    "\n",
    "y_valid_df = pd.DataFrame({'sentiment': y_valid}, columns=['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a46825-4fde-4bca-983f-7b174a37a952",
   "metadata": {},
   "source": [
    "#### Preprocessing : label distribution , tokenization and lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c440098c-cf76-4706-8fee-d0bbd8ec9ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_label_count  = df[df[\"sentiment\"] == \"positive\"].shape[0]\n",
    "negative_label_count = df[df[\"sentiment\"] == \"negative\"].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "21b158f5-27af-457d-8579-60018e90c16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_label_proportion = (positive_label_count / (positive_label_count+ negative_label_count))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3971ed7c-d887-4fa8-9d17-cb85b661bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_label_proportion= (negative_label_count / (positive_label_count+ negative_label_count))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3ae412b-7ce4-45a9-8305-514d81650505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la proportion de sentiments positives est de  50.0\n",
      "la proportion de sentiments négatifs est de  50.0\n"
     ]
    }
   ],
   "source": [
    "print('la proportion de sentiments positives est de ', positive_label_proportion)\n",
    "print('la proportion de sentiments négatifs est de ', negative_label_proportion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf9d282c-868b-4946-a8e4-3cbce39a45f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on constate on a autant de labels positifs que de labels négatifs\n"
     ]
    }
   ],
   "source": [
    "print(\"on constate on a autant de labels positifs que de labels négatifs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "32798eaa-6822-4029-9aee-5c6ce87ec9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current pipeline:\n",
      "  tok2vec\n",
      "  tagger\n",
      "  lemmatizer\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "try:\n",
    "    #rem: enable does not seem to work, don't know why\n",
    "    nlp = spacy.load(\"en_core_web_sm\") #, enable=[\"tok2vec\", \"morphologizer\", \"lemmatizer\"])\n",
    "except OSError:\n",
    "    !python -m spacy download fr_core_news_md\n",
    "    nlp = spacy.load(\"en_core_web_sm\") #, enable=[\"tok2vec\", \"morphologizer\", \"lemmatizer\"])\n",
    "\n",
    "# we won't need ner, parser, attribute_ruler\n",
    "# NB: tok2vec and morphologizer seem to be necessary for lemmatization\n",
    "nlp.remove_pipe(\"ner\")\n",
    "nlp.remove_pipe(\"parser\")\n",
    "nlp.remove_pipe(\"attribute_ruler\")\n",
    "print('Current pipeline:\\n  '+'\\n  '.join(nlp.pipe_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1c2e24e6-3670-4775-bcdb-8aeeec091782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text) :\n",
    "    doc = nlp(text)\n",
    "    tokens =[token.text for token in doc ]\n",
    "    return tokens\n",
    "\n",
    "def lemmatize_text(text) :\n",
    "    doc = nlp(text)\n",
    "    lemmas = [token.lemma_ for token in doc ]\n",
    "    return lemmas \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "723a65a8-5560-4f7c-b865-5c77ca9ee58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moustapha/.local/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "X_train_df['tokens'] = X_train_df['review'].apply(tokenize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "47ed6514-486e-4b82-b37e-53b6d36af1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moustapha/.local/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 55s, sys: 5.97 s, total: 8min 1s\n",
      "Wall time: 8min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_df['lemmas'] = X_train_df['review'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5afeb3dc-ff93-4a46-af1a-b0ee0000475e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>tokens</th>\n",
       "      <th>lemmas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As much as I love trains, I couldn't stomach t...</td>\n",
       "      <td>[As, much, as, I, love, trains, ,, I, could, n...</td>\n",
       "      <td>[as, much, as, i, love, trains, ,, i, could, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This was a very good PPV, but like Wrestlemani...</td>\n",
       "      <td>[This, was, a, very, good, PPV, ,, but, like, ...</td>\n",
       "      <td>[this, was, a, very, good, ppv, ,, but, like, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not finding the right words is everybody's pro...</td>\n",
       "      <td>[Not, finding, the, right, words, is, everybod...</td>\n",
       "      <td>[not, finding, the, right, words, is, everybod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm really suprised this movie didn't get a hi...</td>\n",
       "      <td>[I, 'm, really, suprised, this, movie, did, n'...</td>\n",
       "      <td>[i, 'm, really, suprised, this, movie, did, n'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'll start by confessing that I tend to really...</td>\n",
       "      <td>[I, 'll, start, by, confessing, that, I, tend,...</td>\n",
       "      <td>[i, 'll, start, by, confessing, that, i, tend,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34995</th>\n",
       "      <td>`Shadow Magic' recaptures the joy and amazemen...</td>\n",
       "      <td>[`, Shadow, Magic, ', recaptures, the, joy, an...</td>\n",
       "      <td>[`, shadow, magic, ', recaptures, the, joy, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34996</th>\n",
       "      <td>I found this movie to be quite enjoyable and f...</td>\n",
       "      <td>[I, found, this, movie, to, be, quite, enjoyab...</td>\n",
       "      <td>[i, found, this, movie, to, be, quite, enjoyab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34997</th>\n",
       "      <td>Avoid this one! It is a terrible movie. So wha...</td>\n",
       "      <td>[Avoid, this, one, !, It, is, a, terrible, mov...</td>\n",
       "      <td>[avoid, this, one, !, it, is, a, terrible, mov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>This production was quite a surprise for me. I...</td>\n",
       "      <td>[This, production, was, quite, a, surprise, fo...</td>\n",
       "      <td>[this, production, was, quite, a, surprise, fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34999</th>\n",
       "      <td>This is a decent movie. Although little bit sh...</td>\n",
       "      <td>[This, is, a, decent, movie, ., Although, litt...</td>\n",
       "      <td>[this, is, a, decent, movie, ., although, litt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  \\\n",
       "0      As much as I love trains, I couldn't stomach t...   \n",
       "1      This was a very good PPV, but like Wrestlemani...   \n",
       "2      Not finding the right words is everybody's pro...   \n",
       "3      I'm really suprised this movie didn't get a hi...   \n",
       "4      I'll start by confessing that I tend to really...   \n",
       "...                                                  ...   \n",
       "34995  `Shadow Magic' recaptures the joy and amazemen...   \n",
       "34996  I found this movie to be quite enjoyable and f...   \n",
       "34997  Avoid this one! It is a terrible movie. So wha...   \n",
       "34998  This production was quite a surprise for me. I...   \n",
       "34999  This is a decent movie. Although little bit sh...   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [As, much, as, I, love, trains, ,, I, could, n...   \n",
       "1      [This, was, a, very, good, PPV, ,, but, like, ...   \n",
       "2      [Not, finding, the, right, words, is, everybod...   \n",
       "3      [I, 'm, really, suprised, this, movie, did, n'...   \n",
       "4      [I, 'll, start, by, confessing, that, I, tend,...   \n",
       "...                                                  ...   \n",
       "34995  [`, Shadow, Magic, ', recaptures, the, joy, an...   \n",
       "34996  [I, found, this, movie, to, be, quite, enjoyab...   \n",
       "34997  [Avoid, this, one, !, It, is, a, terrible, mov...   \n",
       "34998  [This, production, was, quite, a, surprise, fo...   \n",
       "34999  [This, is, a, decent, movie, ., Although, litt...   \n",
       "\n",
       "                                                  lemmas  \n",
       "0      [as, much, as, i, love, trains, ,, i, could, n...  \n",
       "1      [this, was, a, very, good, ppv, ,, but, like, ...  \n",
       "2      [not, finding, the, right, words, is, everybod...  \n",
       "3      [i, 'm, really, suprised, this, movie, did, n'...  \n",
       "4      [i, 'll, start, by, confessing, that, i, tend,...  \n",
       "...                                                  ...  \n",
       "34995  [`, shadow, magic, ', recaptures, the, joy, an...  \n",
       "34996  [i, found, this, movie, to, be, quite, enjoyab...  \n",
       "34997  [avoid, this, one, !, it, is, a, terrible, mov...  \n",
       "34998  [this, production, was, quite, a, surprise, fo...  \n",
       "34999  [this, is, a, decent, movie, ., although, litt...  \n",
       "\n",
       "[35000 rows x 3 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "24c7ca01-fe54-46d9-bed9-2b94a6694a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire pour les tokens  : 146293\n",
      "Taille du vocabulaire pour les lemmes : 121716\n"
     ]
    }
   ],
   "source": [
    "tokens_vocab_size = len(set(token for tokens in X_train_df['tokens'] for token in tokens))\n",
    "lemmas_vocab_size = len(set(lemma for lemmas in X_train_df['lemmas'] for lemma in lemmas))\n",
    "print(\"Taille du vocabulaire pour les tokens  :\", tokens_vocab_size)\n",
    "print(\"Taille du vocabulaire pour les lemmes :\", lemmas_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a78f7e-5dd1-484b-b89e-cbcd14dbf8b6",
   "metadata": {},
   "source": [
    "#### Bag-of-Words\" (BoW) vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18058daa-ed03-4bff-b3fc-2f50a98b614d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
